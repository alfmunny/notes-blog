---
categories:
  - notes
date: 2019-10-14 18:14:28
---

#DLPyTorch4.1 - 4.3. Linear function of a linear function is itself always linear. So we need add some non linearity in to the hidden layer. That is the activation function, so we can't merge two layers into one. And we get a multilayer perceptron!
